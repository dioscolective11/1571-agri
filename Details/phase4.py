# -*- coding: utf-8 -*-
"""phase4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UnfsUddGzRq8aFZ5-ap5IJuEcA4Cg36I
"""

import csv
import plotly.graph_objects as go
import plotly.io as pio
import ipywidgets as widgets
from IPython.display import display

def get_groundwater_data(state, district):
    data = []
    try:
        with open('/content/District_Statewise_Well_Final.csv', 'r') as file:
            reader = csv.reader(file)
            header = next(reader)  # Get the header row

            # Normalize header names to handle case and spaces
            header = [col.strip() for col in header]

            # Find the indices of the required columns based on exact header names
            state_index = header.index('NAME OF STATE')
            district_index = header.index('NAME OF DISTRICT')
            recharge_monsoon_rainfall_index = header.index('Recharge from rainfall During Monsoon Season')
            recharge_monsoon_other_index = header.index('Recharge from other sources During Monsoon Season')
            recharge_nonmonsoon_rainfall_index = header.index('Recharge from rainfall During Non Monsoon Season')
            recharge_nonmonsoon_other_index = header.index('Recharge from other sources During Non Monsoon Season')
            total_annual_recharge_index = header.index('Total Annual Ground Water Recharge')
            available_ground_water_index = header.index('Available Ground Water')
            extraction_irrigation_index = header.index('Current Annual Ground Water Extraction For Irrigation')
            total_ground_water_index = header.index('Total Ground Water')
            net_availability_index = header.index('Net Ground Water Availability for future use')
            stage_extraction_index = header.index('Stage of Ground Water Extraction (%)')

            for row in reader:
                if row[state_index].strip() == state.strip() and row[district_index].strip() == district.strip():
                    data_row = {
                        'Recharge from rainfall During Monsoon Season': float(row[recharge_monsoon_rainfall_index]),
                        'Recharge from other sources During Monsoon Season': float(row[recharge_monsoon_other_index]),
                        'Recharge from rainfall During Non Monsoon Season': float(row[recharge_nonmonsoon_rainfall_index]),
                        'Recharge from other sources During Non Monsoon Season': float(row[recharge_nonmonsoon_other_index]),
                        'Total Annual Ground Water Recharge': float(row[total_annual_recharge_index]),
                        'Available Ground Water': float(row[available_ground_water_index]),
                        'Current Annual Ground Water Extraction For Irrigation': float(row[extraction_irrigation_index]),
                        'Total Ground Water': float(row[total_ground_water_index]),
                        'Net Ground Water Availability for future use': float(row[net_availability_index]),
                        'Stage of Ground Water Extraction (%)': float(row[stage_extraction_index])
                    }
                    data.append(data_row)
    except FileNotFoundError:
        print("File not found. Please upload the correct file.")
    except Exception as e:
        print(f"An error occurred: {e}")
    return data

def get_climatic_data(state, district):
    dates = []
    cumulative_actual = []
    cumulative_normal = []
    cumulative_deviation = []
    try:
        with open('/content/rainfall_District Wise Timeseries_1725481887131.csv', 'r') as file:
            reader = csv.reader(file)
            header = next(reader)  # Get the header row

            # Normalize header names to handle case and spaces
            header = [col.strip() for col in header]

            # Find the indices of the required columns based on exact header names
            state_index = header.index('NAME OF STATE')
            district_index = header.index('NAME OF DISTRICT')
            cumulative_actual_index = header.index('Cumulative Actual (mm) (2017-2023)')
            cumulative_normal_index = header.index('Cumulative Normal (mm)(2017-2023)')
            cumulative_deviation_index = header.index('Cumulative Deviation (mm) (2017-2023)')

            for row in reader:
                if row[state_index].strip() == state.strip() and row[district_index].strip() == district.strip():
                    dates.append(row[0])  # Assuming the date or time column is the first one
                    cumulative_actual.append(float(row[cumulative_actual_index]))
                    cumulative_normal.append(float(row[cumulative_normal_index]))
                    cumulative_deviation.append(float(row[cumulative_deviation_index]))
    except FileNotFoundError:
        print("File not found. Please upload the correct file.")
    except Exception as e:
        print(f"An error occurred: {e}")
    return dates, cumulative_actual, cumulative_normal, cumulative_deviation

def get_seasonal_crop_predictions(state, district, season):
    crops = []
    predictions = []
    try:
        with open('/content/crop_production.csv', 'r') as file:
            reader = csv.reader(file)
            header = next(reader)  # Get the header row

            # Normalize header names to handle case and spaces
            header = [col.strip() for col in header]

            # Find the indices of the required columns based on exact header names
            state_index = header.index('NAME OF STATE')
            district_index = header.index('NAME OF DISTRICT')
            season_index = header.index('SEASON')
            crop_index = header.index('CROP')
            prediction_indices = [header.index(f'Prediction{i}') for i in range(1, 6)]

            for row in reader:
                if row[state_index].strip() == state.strip() and row[district_index].strip() == district.strip() and row[season_index].strip() == season:
                    crops.append(row[crop_index])
                    for i, idx in enumerate(prediction_indices):
                        predictions.append(float(row[idx]))
    except FileNotFoundError:
        print("File not found. Please upload the correct file.")
    except Exception as e:
        print(f"An error occurred: {e}")
    return crops, predictions

def plot_pie_chart(data):
    if not data:
        print("No data available to plot.")
        return

    # Assuming we only need the first record (since we're querying by state and district)
    data_row = data[0]

    # Prepare data for the pie chart
    labels = data_row.keys()
    sizes = data_row.values()

    # Create a pie chart
    fig = go.Figure(data=[go.Pie(labels=list(labels), values=list(sizes), hole=0.3)])
    fig.update_layout(title=f"Groundwater Data for {state} - {district}")

    # Show the pie chart
    pio.show(fig)

def plot_bar_graph(dates, cumulative_actual, cumulative_normal, cumulative_deviation):
    if not dates or not cumulative_actual or not cumulative_normal or not cumulative_deviation:
        print("No data available to plot.")
        return

    # Create a bar graph
    fig = go.Figure()
    fig.add_trace(go.Bar(x=dates, y=cumulative_actual, name='Cumulative Actual'))
    fig.add_trace(go.Bar(x=dates, y=cumulative_normal, name='Cumulative Normal'))
    fig.add_trace(go.Bar(x=dates, y=cumulative_deviation, name='Cumulative Deviation'))

    fig.update_layout(title=f"Comparison of Cumulative Actual, Normal, and Deviation Rainfall for {state} - {district}",
                      xaxis_title='Date',
                      yaxis_title='Cumulative (mm)',
                      barmode='group')

    # Show the bar graph
    pio.show(fig)

def plot_seasonal_crop_predictions(crops, predictions):
    if not crops or not predictions:
        print("No seasonal crop prediction data available.")
        return

    # Create a bar graph for seasonal crop predictions
    fig = go.Figure()
    for i, crop in enumerate(crops):
        fig.add_trace(go.Bar(x=[crop], y=[predictions[i]], name=crop))

    fig.update_layout(title=f"Seasonal Crop Predictions for {state} - {district}",
                      xaxis_title='Crops',
                      yaxis_title='Predictions (mm)')

    # Show the bar graph
    pio.show(fig)

# Example usage
state = input("Enter the state: ")
district = input("Enter the district: ")

# Get and plot groundwater data
groundwater_data = get_groundwater_data(state, district)
if groundwater_data:
    plot_pie_chart(groundwater_data)
else:
    print("No groundwater data found for the given state and district.")

# Get and plot climatic data
dates, cumulative_actual, cumulative_normal, cumulative_deviation = get_climatic_data(state, district)
if dates and cumulative_actual and cumulative_normal and cumulative_deviation:
    plot_bar_graph(dates, cumulative_actual, cumulative_normal, cumulative_deviation)
else:
    print("No climatic data found for the given state and district.")

# Add interactive widget for season selection and crop predictions
season_dropdown = widgets.Dropdown(
    options=['Kharif', 'Whole Year', 'Autumn', 'Rabi', 'Summer', 'Winter'],
    value='Kharif',
    description='Select Season:'
)

def on_season_change(change):
    season = change.new
    crops, predictions = get_seasonal_crop_predictions(state, district, season)
    plot_seasonal_crop_predictions(crops, predictions)

season_dropdown.observe(on_season_change, names='value')
display(season_dropdown)

import csv
import matplotlib.pyplot as plt
import plotly.graph_objects as go
import plotly.io as pio
import ipywidgets as widgets
from IPython.display import display

# Function to get groundwater data based on state and district
def get_groundwater_data(state, district):
    data = []
    try:
        with open('/content/District_Statewise_Well_Final.csv', 'r') as file:
            reader = csv.reader(file)
            header = next(reader)  # Get the header row

            # Normalize header names to handle case and spaces
            header = [col.strip() for col in header]

            # Find the indices of the required columns based on exact header names
            state_index = header.index('NAME OF STATE')
            district_index = header.index('NAME OF DISTRICT')
            recharge_monsoon_rainfall_index = header.index('Recharge from rainfall During Monsoon Season')
            recharge_monsoon_other_index = header.index('Recharge from other sources During Monsoon Season')
            recharge_nonmonsoon_rainfall_index = header.index('Recharge from rainfall During Non Monsoon Season')
            recharge_nonmonsoon_other_index = header.index('Recharge from other sources During Non Monsoon Season')
            total_annual_recharge_index = header.index('Total Annual Ground Water Recharge')
            available_ground_water_index = header.index('Available Ground Water')
            extraction_irrigation_index = header.index('Current Annual Ground Water Extraction For Irrigation')
            total_ground_water_index = header.index('Total Ground Water')
            net_availability_index = header.index('Net Ground Water Availability for future use')
            stage_extraction_index = header.index('Stage of Ground Water Extraction (%)')

            for row in reader:
                if (row[state_index].strip() == state.strip() and
                    row[district_index].strip() == district.strip()):
                    data_row = {
                        'Recharge from rainfall During Monsoon Season': float(row[recharge_monsoon_rainfall_index]),
                        'Recharge from other sources During Monsoon Season': float(row[recharge_monsoon_other_index]),
                        'Recharge from rainfall During Non Monsoon Season': float(row[recharge_nonmonsoon_rainfall_index]),
                        'Recharge from other sources During Non Monsoon Season': float(row[recharge_nonmonsoon_other_index]),
                        'Total Annual Ground Water Recharge': float(row[total_annual_recharge_index]),
                        'Available Ground Water': float(row[available_ground_water_index]),
                        'Current Annual Ground Water Extraction For Irrigation': float(row[extraction_irrigation_index]),
                        'Total Ground Water': float(row[total_ground_water_index]),
                        'Net Ground Water Availability for future use': float(row[net_availability_index]),
                        'Stage of Ground Water Extraction (%)': float(row[stage_extraction_index])
                    }
                    data.append(data_row)
    except FileNotFoundError:
        print("File not found. Please upload the correct file.")
    except Exception as e:
        print(f"An error occurred: {e}")
    return data

# Function to get climatic data based on state and district
def get_climatic_data(state, district):
    dates = []
    cumulative_actual = []
    cumulative_normal = []
    cumulative_deviation = []
    try:
        with open('/content/rainfall_District Wise Timeseries_1725481887131.csv', 'r') as file:
            reader = csv.reader(file)
            header = next(reader)  # Get the header row

            # Normalize header names to handle case and spaces
            header = [col.strip() for col in header]

            # Find the indices of the required columns based on exact header names
            state_index = header.index('NAME OF STATE')
            district_index = header.index('NAME OF DISTRICT')
            cumulative_actual_index = header.index('Cumulative Actual (mm) (2017-2023)')
            cumulative_normal_index = header.index('Cumulative Normal (mm)(2017-2023)')
            cumulative_deviation_index = header.index('Cumulative Deviation (mm) (2017-2023)')

            for row in reader:
                if (row[state_index].strip() == state.strip() and
                    row[district_index].strip() == district.strip()):
                    dates.append(row[0])  # Assuming the date or time column is the first one
                    cumulative_actual.append(float(row[cumulative_actual_index]))
                    cumulative_normal.append(float(row[cumulative_normal_index]))
                    cumulative_deviation.append(float(row[cumulative_deviation_index]))
    except FileNotFoundError:
        print("File not found. Please upload the correct file.")
    except Exception as e:
        print(f"An error occurred: {e}")
    return dates, cumulative_actual, cumulative_normal, cumulative_deviation

# Function to get crop data based on state, district, and season
def get_seasonal_crop_data(state, district, season):
    crops = []
    try:
        with open('/content/seasonal_crop_data.csv', 'r') as file:
            reader = csv.reader(file)
            header = next(reader)  # Get the header row

            # Normalize header names to handle case and spaces
            header = [col.strip() for col in header]

            # Find the indices of the required columns based on exact header names
            state_index = header.index('NAME OF STATE')
            district_index = header.index('NAME OF DISTRICT')
            season_index = header.index('SEASON')
            crop_index = header.index('CROP')

            for row in reader:
                if (row[state_index].strip() == state.strip() and
                    row[district_index].strip() == district.strip() and
                    row[season_index].strip() == season):
                    crops.append(row[crop_index])

        if not crops:
            print(f"No crop data available for {state} - {district} during {season}.")
    except FileNotFoundError:
        print("File not found. Please upload the correct file.")
    except Exception as e:
        print(f"An error occurred: {e}")
    return crops

# Function to plot pie chart for groundwater data
def plot_pie_chart(data):
    if not data:
        print("No data available to plot.")
        return

    # Assuming we only need the first record (since we're querying by state and district)
    data_row = data[0]

    # Prepare data for the pie chart
    labels = data_row.keys()
    sizes = data_row.values()

    # Create a pie chart
    plt.figure(figsize=(10, 7))
    plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=140)
    plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.

    # Show the pie chart
    plt.title(f"Groundwater Data for {state} - {district}")
    plt.show()

# Function to plot bar graph for climatic data
def plot_bar_graph(dates, cumulative_actual, cumulative_normal, cumulative_deviation):
    if not dates or not cumulative_actual or not cumulative_normal or not cumulative_deviation:
        print("No data available to plot.")
        return

    x = range(len(dates))

    # Create a bar graph
    plt.figure(figsize=(14, 8))
    plt.bar(x, cumulative_actual, width=0.25, label='Cumulative Actual', align='center')
    plt.bar([i + 0.25 for i in x], cumulative_normal, width=0.25, label='Cumulative Normal', align='center')
    plt.bar([i + 0.50 for i in x], cumulative_deviation, width=0.25, label='Cumulative Deviation', align='center')

    plt.xlabel('Date')
    plt.ylabel('Cumulative (mm)')
    plt.title(f"Comparison of Cumulative Actual, Normal, and Deviation Rainfall for {state} - {district}")
    plt.xticks([i + 0.25 for i in x], dates, rotation=45)
    plt.legend()
    plt.tight_layout()  # Adjust layout to ensure labels are not cut off

    # Show the bar graph
    plt.show()

# Function to plot bar graph for crop data
def plot_crop_bar_graph(crops):
    if not crops:
        print("No crop data available.")
        return

    # Create a bar graph for crop data
    fig = go.Figure()
    crop_counts = {crop: crops.count(crop) for crop in set(crops)}  # Count occurrences of each crop
    fig.add_trace(go.Bar(x=list(crop_counts.keys()), y=list(crop_counts.values()), name='Crops'))

    fig.update_layout(title=f"Crop Data for {state} - {district}",
                      xaxis_title='Crops',
                      yaxis_title='Count',
                      barmode='group')
    pio.show(fig)

# Function to handle season dropdown changes
def on_season_change(change):
    season = change.new
    crops = get_seasonal_crop_data(state, district, season)
    plot_crop_bar_graph(crops)

# Example usage
state = input("Enter the state: ")
district = input("Enter the district: ")
groundwater_data = get_groundwater_data(state, district)
dates, cumulative_actual, cumulative_normal, cumulative_deviation = get_climatic_data(state, district)

if groundwater_data:
    plot_pie_chart(groundwater_data)
else:
    print("No groundwater data found for the given state and district.")

if dates and cumulative_actual and cumulative_normal and cumulative_deviation:
    plot_bar_graph(dates, cumulative_actual, cumulative_normal, cumulative_deviation)
else:
    print("No climatic data found for the given state and district.")

# Add interactive widget for season selection
season_dropdown = widgets.Dropdown(
    options=['Kharif', 'Whole Year', 'Autumn', 'Rabi', 'Summer', 'Winter'],
    value='Kharif',
    description='Select Season:'
)

season_dropdown.observe(on_season_change, names='value')
display(season_dropdown)

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
import joblib

# Load the data
def load_data(file_path):
    try:
        data = pd.read_csv("Crop_recommendation_final.csv")
        print("Data loaded successfully.")
        return data
    except FileNotFoundError:
        print("File not found. Please upload the correct file.")
        return None
    except Exception as e:
        print(f"An error occurred: {e}")
        return None

# Preprocess the data
def preprocess_data(data):
    try:
        # Check for missing values
        print("Missing values in each column:")
        print(data.isnull().sum())

        # Drop rows with missing values
        data = data.dropna()

        # Encode categorical variables
        le = LabelEncoder()
        data['crop'] = le.fit_transform(data['crop'])

        # Features and target
        X = data[['temperature', 'humidity']]
        y = data['crop']

        # Split the data
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

        # Feature scaling
        scaler = StandardScaler()
        X_train = scaler.fit_transform(X_train)
        X_test = scaler.transform(X_test)

        print("Data preprocessing completed.")
        return X_train, X_test, y_train, y_test, le, scaler
    except Exception as e:
        print(f"An error occurred during preprocessing: {e}")
        return None

# Train the model
def train_model(X_train, y_train):
    try:
        model = RandomForestClassifier(n_estimators=100, random_state=42)
        model.fit(X_train, y_train)
        print("Model training completed.")
        return model
    except Exception as e:
        print(f"An error occurred during training: {e}")
        return None

# Evaluate the model
def evaluate_model(model, X_test, y_test):
    try:
        y_pred = model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        print(f"Model accuracy: {accuracy:.2f}")
    except Exception as e:
        print(f"An error occurred during evaluation: {e}")

# Save the model and scaler
def save_model(model, scaler, le, model_path='crop_predictor_model.joblib'):
    try:
        joblib.dump(model, model_path)
        joblib.dump(scaler, 'scaler.joblib')
        joblib.dump(le, 'label_encoder.joblib')
        print(f"Model, scaler, and label encoder saved to {model_path}.")
    except Exception as e:
        print(f"An error occurred while saving: {e}")

# Load the model and scaler
def load_model(model_path='crop_predictor_model.joblib'):
    try:
        model = joblib.load(model_path)
        scaler = joblib.load('scaler.joblib')
        le = joblib.load('label_encoder.joblib')
        print("Model, scaler, and label encoder loaded successfully.")
        return model, scaler, le
    except FileNotFoundError:
        print("File not found. Please upload the correct file.")
        return None, None, None
    except Exception as e:
        print(f"An error occurred while loading: {e}")
        return None, None, None

# Predict crops based on temperature and humidity
def predict_crop(model, scaler, le, temperature, humidity):
    try:
        features = [[temperature, humidity]]
        features_scaled = scaler.transform(features)
        prediction = model.predict(features_scaled)
        crop = le.inverse_transform(prediction)
        return crop[0]
    except Exception as e:
        print(f"An error occurred during prediction: {e}")
        return None

# Main code
if __name__ == "__main__":
    # Load and preprocess data
    data = load_data('/content/seasonal_crop_data.csv')
    if data is not None:
        X_train, X_test, y_train, y_test, le, scaler = preprocess_data(data)

        # Train and evaluate the model
        model = train_model(X_train, y_train)
        if model is not None:
            evaluate_model(model, X_test, y_test)

            # Save the model, scaler, and label encoder
            save_model(model, scaler, le)

            # Example prediction
            temperature = float(input("Enter temperature: "))
            humidity = float(input("Enter humidity: "))
            crop = predict_crop(model, scaler, le, temperature, humidity)
            if crop:
                print(f"Predicted crop: {crop}")

"""FINAL CODE"""

# final code
import csv
import pandas as pd
import plotly.graph_objects as go
import plotly.io as pio
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
import joblib
import ipywidgets as widgets
from IPython.display import display

# Load groundwater data
def get_groundwater_data(state, district):
    data = []
    try:
        with open('/content/District_Statewise_Well_Final.csv', 'r') as file:
            reader = csv.reader(file)
            header = next(reader)
            header = [col.strip() for col in header]
            state_index = header.index('NAME OF STATE')
            district_index = header.index('NAME OF DISTRICT')
            recharge_monsoon_rainfall_index = header.index('Recharge from rainfall During Monsoon Season')
            recharge_monsoon_other_index = header.index('Recharge from other sources During Monsoon Season')
            recharge_nonmonsoon_rainfall_index = header.index('Recharge from rainfall During Non Monsoon Season')
            recharge_nonmonsoon_other_index = header.index('Recharge from other sources During Non Monsoon Season')
            total_annual_recharge_index = header.index('Total Annual Ground Water Recharge')
            available_ground_water_index = header.index('Available Ground Water')
            extraction_irrigation_index = header.index('Current Annual Ground Water Extraction For Irrigation')
            total_ground_water_index = header.index('Total Ground Water')
            net_availability_index = header.index('Net Ground Water Availability for future use')
            stage_extraction_index = header.index('Stage of Ground Water Extraction (%)')

            for row in reader:
                if row[state_index].strip() == state.strip() and row[district_index].strip() == district.strip():
                    data_row = {
                        'Recharge from rainfall During Monsoon Season': float(row[recharge_monsoon_rainfall_index]),
                        'Recharge from other sources During Monsoon Season': float(row[recharge_monsoon_other_index]),
                        'Recharge from rainfall During Non Monsoon Season': float(row[recharge_nonmonsoon_rainfall_index]),
                        'Recharge from other sources During Non Monsoon Season': float(row[recharge_nonmonsoon_other_index]),
                        'Total Annual Ground Water Recharge': float(row[total_annual_recharge_index]),
                        'Available Ground Water': float(row[available_ground_water_index]),
                        'Current Annual Ground Water Extraction For Irrigation': float(row[extraction_irrigation_index]),
                        'Total Ground Water': float(row[total_ground_water_index]),
                        'Net Ground Water Availability for future use': float(row[net_availability_index]),
                        'Stage of Ground Water Extraction (%)': float(row[stage_extraction_index])
                    }
                    data.append(data_row)
    except FileNotFoundError:
        print("File not found. Please upload the correct file.")
    except Exception as e:
        print(f"An error occurred: {e}")
    return data

# Load climatic data
def get_climatic_data(state, district):
    dates = []
    cumulative_actual = []
    cumulative_normal = []
    cumulative_deviation = []
    try:
        with open('/content/rainfall_District Wise Timeseries_1725481887131.csv', 'r') as file:
            reader = csv.reader(file)
            header = next(reader)
            header = [col.strip() for col in header]
            state_index = header.index('NAME OF STATE')
            district_index = header.index('NAME OF DISTRICT')
            cumulative_actual_index = header.index('Cumulative Actual (mm) (2017-2023)')
            cumulative_normal_index = header.index('Cumulative Normal (mm)(2017-2023)')
            cumulative_deviation_index = header.index('Cumulative Deviation (mm) (2017-2023)')

            for row in reader:
                if row[state_index].strip() == state.strip() and row[district_index].strip() == district.strip():
                    dates.append(row[0])
                    cumulative_actual.append(float(row[cumulative_actual_index]))
                    cumulative_normal.append(float(row[cumulative_normal_index]))
                    cumulative_deviation.append(float(row[cumulative_deviation_index]))
    except FileNotFoundError:
        print("File not found. Please upload the correct file.")
    except Exception as e:
        print(f"An error occurred: {e}")
    return dates, cumulative_actual, cumulative_normal, cumulative_deviation

# Load crop data
def load_data(file_path):
    try:
        data = pd.read_csv(file_path)
        print("Data loaded successfully.")
        return data
    except FileNotFoundError:
        print("File not found. Please upload the correct file.")
        return None
    except Exception as e:
        print(f"An error occurred: {e}")
        return None

# Preprocess data
def preprocess_data(data):
    try:
        print("Missing values in each column:")
        print(data.isnull().sum())
        data = data.dropna()
        le = LabelEncoder()
        data['crop'] = le.fit_transform(data['crop'])
        X = data[['temperature', 'humidity']]
        y = data['crop']
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
        scaler = StandardScaler()
        X_train = scaler.fit_transform(X_train)
        X_test = scaler.transform(X_test)
        print("Data preprocessing completed.")
        return X_train, X_test, y_train, y_test, le, scaler
    except Exception as e:
        print(f"An error occurred during preprocessing: {e}")
        return None

# Train model
def train_model(X_train, y_train):
    try:
        model = RandomForestClassifier(n_estimators=100, random_state=42)
        model.fit(X_train, y_train)
        print("Model training completed.")
        return model
    except Exception as e:
        print(f"An error occurred during training: {e}")
        return None

# Evaluate model
def evaluate_model(model, X_test, y_test):
    try:
        y_pred = model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        print(f"Model accuracy: {accuracy:.2f}")
    except Exception as e:
        print(f"An error occurred during evaluation: {e}")

# Save model and scaler
def save_model(model, scaler, le, model_path='crop_predictor_model.joblib'):
    try:
        joblib.dump(model, model_path)
        joblib.dump(scaler, 'scaler.joblib')
        joblib.dump(le, 'label_encoder.joblib')
        print(f"Model, scaler, and label encoder saved to {model_path}.")
    except Exception as e:
        print(f"An error occurred while saving: {e}")

# Load model and scaler
def load_model(model_path='crop_predictor_model.joblib'):
    try:
        model = joblib.load(model_path)
        scaler = joblib.load('scaler.joblib')
        le = joblib.load('label_encoder.joblib')
        print("Model, scaler, and label encoder loaded successfully.")
        return model, scaler, le
    except FileNotFoundError:
        print("File not found. Please upload the correct file.")
        return None, None, None
    except Exception as e:
        print(f"An error occurred while loading: {e}")
        return None, None, None

# Predict crops
def predict_crop(model, scaler, le, temperature, humidity):
    try:
        features = [[temperature, humidity]]
        features_scaled = scaler.transform(features)
        prediction = model.predict(features_scaled)
        crop = le.inverse_transform(prediction)
        return crop[0]
    except Exception as e:
        print(f"An error occurred during prediction: {e}")
        return None

# Plot groundwater data
def plot_pie_chart(data, state, district):
    if not data:
        print("No data available to plot.")
        return

    data_row = data[0]
    labels = data_row.keys()
    sizes = data_row.values()

    fig = go.Figure(data=[go.Pie(labels=list(labels), values=list(sizes), hole=0.3)])
    fig.update_layout(title=f"Groundwater Data for {state} - {district}")
    pio.show(fig)

# Plot climatic data
def plot_bar_graph(dates, cumulative_actual, cumulative_normal, cumulative_deviation, state, district):
    if not dates or not cumulative_actual or not cumulative_normal or not cumulative_deviation:
        print("No data available to plot.")
        return

    fig = go.Figure()
    fig.add_trace(go.Bar(x=dates, y=cumulative_actual, name='Cumulative Actual'))
    fig.add_trace(go.Bar(x=dates, y=cumulative_normal, name='Cumulative Normal'))
    fig.add_trace(go.Bar(x=dates, y=cumulative_deviation, name='Cumulative Deviation'))

    fig.update_layout(title=f"Comparison of Cumulative Actual, Normal, and Deviation Rainfall for {state} - {district}",
                      xaxis_title='Date',
                      yaxis_title='Cumulative (mm)',
                      barmode='group')

    pio.show(fig)

# Main code
if __name__ == "__main__":
    state = input("Enter the state: ")
    district = input("Enter the district: ")

    # Get and plot groundwater data
    groundwater_data = get_groundwater_data(state, district)
    if groundwater_data:
        plot_pie_chart(groundwater_data, state, district)
    else:
        print("No groundwater data found for the given state and district.")

    # Get and plot climatic data
    dates, cumulative_actual, cumulative_normal, cumulative_deviation = get_climatic_data(state, district)
    if dates and cumulative_actual and cumulative_normal and cumulative_deviation:
        plot_bar_graph(dates, cumulative_actual, cumulative_normal, cumulative_deviation, state, district)
    else:
        print("No climatic data found for the given state and district.")

    # Load and preprocess crop data
    data = load_data('/content/Crop_recommendation_final.csv')
    if data is not None:
        X_train, X_test, y_train, y_test, le, scaler = preprocess_data(data)
        model = train_model(X_train, y_train)
        if model is not None:
            evaluate_model(model, X_test, y_test)
            save_model(model, scaler, le)

            # Predict crops based on user input
            temperature = float(input("Enter temperature: "))
            humidity = float(input("Enter humidity: "))
            crop = predict_crop(model, scaler, le, temperature, humidity)
            if crop:
                print(f"Predicted crop: {crop}")